from typing import Dict, Any, Optional
import os
from utils.logger import log_event

def create_agent_a2a(agent_config: Dict[str, Any], output_base_path: Optional[str] = None) -> Dict[str, Any]:
    """
    Generates a fully functional, A2A-compatible agent Python file.
    
    The generated agent:
    - Uses the selected LLM model from agent configuration
    - Implements the agent's system prompt and capabilities
    - Is easily pluggable into A2A multi-agent systems
    - Can be imported and used standalone or in agent networks
    
    Args:
        agent_config: Agent configuration dictionary (must include 'selected_model')
        output_base_path: Base directory for generated agents (defaults to 'agents/generated')
    """
    log_event("AGENT_GENERATION_START", agent_id=agent_config["agent_id"])
    
    # Validate required model configuration
    if "selected_model" not in agent_config:
        raise ValueError(
            "Agent configuration must include 'selected_model'. "
            "Ensure llm_selector has been run and model is selected."
        )
    
    model_name = agent_config["selected_model"]
    agent_name = agent_config["agent_type"].replace(" ", "_").lower()
    file_name = f"{agent_name}_{agent_config['agent_id'][:8]}.py"
    
    # Construct output path: base_path/agent_name/
    if output_base_path is None:
        output_base_path = "agents/generated"
    
    output_path = os.path.join(output_base_path, agent_name)
    
    # Ensure output directory exists
    os.makedirs(output_path, exist_ok=True)
    full_path = os.path.join(output_path, file_name)
    
    # Generate comprehensive Python code for A2A agent
    code = f'''"""
Auto-generated Agent: {agent_config['agent_type']}
Generated by Agent Creator System
Agent ID: {agent_config['agent_id']}

This agent is designed to be pluggable into A2A (Agent-to-Agent) systems.
"""

import os
from typing import Dict, Any, Optional
from google import genai
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


class {agent_name.title().replace('_', '')}Agent:
    """
    {agent_config['agent_type']} Agent
    
    Capabilities:
{chr(10).join(f"    - {cap}" for cap in agent_config['capabilities'])}
    
    System Prompt:
    {agent_config['system_prompt']}
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize the agent with LLM client."""
        self.agent_id = "{agent_config['agent_id']}"
        self.agent_type = "{agent_config['agent_type']}"
        self.capabilities = {agent_config['capabilities']}
        self.system_prompt = """{agent_config['system_prompt']}"""
        
        # Initialize LLM client
        api_key = api_key or os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("API key required. Set GOOGLE_API_KEY or GEMINI_API_KEY environment variable.")
        
        self.client = genai.Client(api_key=api_key)
        self.model_name = "{model_name}"
    
    def process(self, message: str, context: Optional[Dict[str, Any]] = None) -> str:
        """
        Main processing method for A2A communication.
        
        Args:
            message: Input message/query from user or another agent
            context: Optional context dictionary for multi-agent scenarios
            
        Returns:
            Agent's response as a string
        """
        # Construct full prompt with system instruction
        full_prompt = f"{{self.system_prompt}}\\n\\nUser Query: {{message}}"
        
        if context:
            full_prompt += f"\\n\\nContext: {{context}}"
        
        try:
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=full_prompt
            )
            return response.text
        except Exception as e:
            return f"Error processing request: {{str(e)}}"
    
    def get_capabilities(self) -> Dict[str, Any]:
        """Return agent capabilities for A2A discovery."""
        return {{
            "agent_id": self.agent_id,
            "agent_type": self.agent_type,
            "capabilities": self.capabilities,
            "model": self.model_name
        }}
    
    def __call__(self, message: str, **kwargs) -> str:
        """Make agent callable for easy A2A integration."""
        return self.process(message, context=kwargs.get('context'))


# Factory function for easy instantiation
def create_agent(api_key: Optional[str] = None) -> {agent_name.title().replace('_', '')}Agent:
    """Create and return an instance of this agent."""
    return {agent_name.title().replace('_', '')}Agent(api_key=api_key)


# A2A Protocol Interface
class A2AInterface:
    """
    Standard A2A interface for multi-agent systems.
    Allows this agent to communicate with other agents.
    """
    
    def __init__(self, agent: {agent_name.title().replace('_', '')}Agent):
        self.agent = agent
    
    def send_message(self, message: str, recipient_id: Optional[str] = None) -> str:
        """Send message to another agent or process locally."""
        # In a full A2A system, this would route to the recipient
        # For now, process locally
        return self.agent.process(message)
    
    def receive_message(self, message: str, sender_id: str) -> str:
        """Receive and process message from another agent."""
        context = {{"sender_id": sender_id}}
        return self.agent.process(message, context=context)
    
    def broadcast(self, message: str) -> str:
        """Broadcast message to agent network."""
        # In full A2A system, this would broadcast to all agents
        return self.agent.process(message)


# Example usage and testing
if __name__ == "__main__":
    # Create agent instance
    agent = create_agent()
    
    print(f"Agent initialized: {{agent.agent_type}}")
    print(f"Agent ID: {{agent.agent_id}}")
    print(f"Capabilities: {{agent.capabilities}}")
    print("-" * 50)
    
    # Test basic interaction
    test_query = "Hello! What can you help me with?"
    response = agent(test_query)
    print(f"Query: {{test_query}}")
    print(f"Response: {{response}}")
    print("-" * 50)
    
    # Test A2A interface
    a2a = A2AInterface(agent)
    a2a_response = a2a.receive_message(
        "Can you help with this task?",
        sender_id="agent_123"
    )
    print(f"A2A Response: {{a2a_response}}")
'''
    
    try:
        with open(full_path, "w") as f:
            f.write(code)
            
        log_event("AGENT_GENERATION_SUCCESS", 
                 file_path=full_path,
                 agent_type=agent_config['agent_type'],
                 model=model_name)
        
        return {
            "success": True,
            "endpoint": full_path,
            "agent_id": agent_config["agent_id"],
            "agent_class": f"{agent_name.title().replace('_', '')}Agent"
        }
    except Exception as e:
        log_event("AGENT_GENERATION_ERROR", error=str(e))
        raise
